CS 534 Final Project Code

Generative CNN for raw audio. 

Files:

train.py:   mostly tensorflow boilerplate, we parse arguments and init the computational graph. 
			Once everything is set up, we run the graph, and save parameters every 200 steps. 

ops.py  :   Contains methods for mu-law quantization of audio samples, causal convolutions, 
			and more tensorflow boilerplate for setting up solvers Adam, RMSprop, and SGD

model.py:	Here we define the computational graph to be run. We mostly follow the scheme in https://arxiv.org/pdf/1609.03499.pdf
			However, we change the structure of the output stream, as well as using a different dilation scheme. 
			We also connect the residual outputs of each layer, into the next layer of the stack. We assume the authors did this, 
			but it is not mentioned in the text. 

wavenet_params.json : This defines the number of layers, skip connections, dilation scheme, one hot encoding of input, etc. 
					  A total optimization of this project involves dilation schemes of 1 .. 1024, and hundreds of layers. 
					  This would require a massive GPU cluster, but that's par the course with large models like this. 

We must give credit to Tom Lepaine for his fast wavenet implementation. His generation scheme reduced the computational cost
of generation from the original O(2^L) to O(L) where L is the number of layers. Deepmind needed 90 minutes to generate 1 second 
of audio, we can do it in near linear time with respect to L. 